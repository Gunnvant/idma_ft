## DL Module
- Week 1
    - Day1: Neuron, activation functions, feedforward, feedforward using excel, loss functions, numpy
    - Day2: Gradient Descent, gradient descent to estimate linear regression parameters, logistic regression parameters
    - Day3: Backpropagation on simple neurons, introduction to pytorch, autograd in linear and logistic regression, gradient.tape in tensorflow, simple network training
    - Day4: Writing dataloaders for pytorch, creating a simple model and writing the training loop, writing the testing loop and the inference loop. Creating simple model in tensorfow-keras.
    - Day5: Image data, reading images, exploring channels, flattening image data, building a simple image classifier using both pytorch and tensorflow

- Week 2
    - Day1: Convolutional Neural Networks, Convolution Operation, writting a CNN in pytorch and tensorflow. Convolution arithematic.
    - Day2: Pre-trained models: VGG16 and Resnet, residual connections, transfer learning
    - Day3: Multilabel classification, Object Detection using single shot detectors
    - Day4: Custom Data Labelling (VOTT), handling VOC and COCO data format
    - Day5: Text classification using tfidf, Using tfidf representation to find keywords, text similarity

- Week 3
    - Day1: Naive Bayes Classifier, linear text classifier. Topic Modelling using NMF
    - Day2: Building ngram model for next word suggestion, POS tagging and NER using spacy
    - Day3: Using word vectors to build text classifiers, using rnn and lstm layers
    - Day4: Encoder-decoder models for language translation, 
    - Day5: ??
    
    
 