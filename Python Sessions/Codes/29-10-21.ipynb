{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48ecd5da-4a44-4224-9392-4c975b6d7e1c",
   "metadata": {},
   "source": [
    "### Class Excercise (writer and DictWriter)\n",
    "\n",
    "Use the tweets_assignment.txt to find out how many tweets were posted on 23, 24, 25, 26 December. Write the results in a csv file using the writer or DictWriter class. The file should follow the following format:\n",
    "\n",
    "```csv\n",
    "count_23,count_24,count_25,count_26\n",
    "val1,val2,val3,val4\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f66cc8fa-55f1-45f5-877e-ac310299bb40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Spam', 'Spam', 'Spam', 'Spam', 'Spam', 'Baked Beans']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "['Spam'] * 5 + ['Baked Beans']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c23dabc6-27bc-4edb-be25-983bbabfb97d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "with open('names.csv', 'w', newline='') as csvfile:\n",
    "    columns = ['count_23','count_24','count_25','count_26']\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=columns)\n",
    "    writer.writeheader()\n",
    "    writer.writerow({'count_23':5092 , 'count_24':4079,'count_25':3103,'count_26':1999})\n",
    "    writer.writerow({'count_23':5 , 'count_24':4,'count_25':3,'count_26':1})\n",
    "    writer.writerow({'count_23':5 , 'count_24':4,'count_25':3,'count_26':1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6161b0a9-70b2-4622-b2c3-dcf66be0235c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('names2.csv', 'w', newline='') as csvfile:\n",
    "    spamwriter = csv.writer(csvfile, delimiter=',')\n",
    "    columns = ['count_23','count_24','count_25','count_26']\n",
    "    data = [[5092,4079,3103,1999],[44,56,77,88]]\n",
    "    spamwriter.writerow(columns)\n",
    "    for i in data:\n",
    "        spamwriter.writerow(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "28bf764f-2b85-4a20-aee4-7afba8bf5258",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "con = open(\"../data/sample_json.json\",\"r\")\n",
    "json_string = con.read()\n",
    "con.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3bbc62a7-392f-422a-8f6d-9a56d22055d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = json.loads(json_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "102eaa77-00a5-4f25-9a25-a87e8791b4b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['type', 'metadata', 'features', 'bbox'])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cea08bb7-8b06-4059-b720-fd57a4345cd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'FeatureCollection'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "004b0dea-a38b-421a-afac-13a51d9dff9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'generated': 1626859520000,\n",
       " 'url': 'https://earthquake.usgs.gov/earthquakes/feed/v1.0/summary/all_hour.geojson',\n",
       " 'title': 'USGS All Earthquakes, Past Hour',\n",
       " 'status': 200,\n",
       " 'api': '1.10.3',\n",
       " 'count': 14}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['metadata']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c65567e2-1801-454b-a335-235b3bf2c0b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'type': 'Feature',\n",
       " 'properties': {'mag': 2.1500001,\n",
       "  'place': '3 km ENE of Pāhala, Hawaii',\n",
       "  'time': 1626859250480,\n",
       "  'updated': 1626859447300,\n",
       "  'tz': None,\n",
       "  'url': 'https://earthquake.usgs.gov/earthquakes/eventpage/hv72595567',\n",
       "  'detail': 'https://earthquake.usgs.gov/earthquakes/feed/v1.0/detail/hv72595567.geojson',\n",
       "  'felt': None,\n",
       "  'cdi': None,\n",
       "  'mmi': None,\n",
       "  'alert': None,\n",
       "  'status': 'automatic',\n",
       "  'tsunami': 0,\n",
       "  'sig': 71,\n",
       "  'net': 'hv',\n",
       "  'code': '72595567',\n",
       "  'ids': ',hv72595567,',\n",
       "  'sources': ',hv,',\n",
       "  'types': ',origin,phase-data,',\n",
       "  'nst': 44,\n",
       "  'dmin': None,\n",
       "  'rms': 0.100000001,\n",
       "  'gap': 113,\n",
       "  'magType': 'md',\n",
       "  'type': 'earthquake',\n",
       "  'title': 'M 2.2 - 3 km ENE of Pāhala, Hawaii'},\n",
       " 'geometry': {'type': 'Point',\n",
       "  'coordinates': [-155.451171875, 19.2175006866455, 35.3600006103516]},\n",
       " 'id': 'hv72595567'}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['features'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c526589e-256c-4167-88b6-5ec5808dfbd1",
   "metadata": {},
   "source": [
    "### Extract:\n",
    "\n",
    "- Magnitude\n",
    "- Location\n",
    "- Url\n",
    "\n",
    "Write this in the form of a csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c2654799-c0b6-4ea9-9b68-2e4a8199bee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "mag = []\n",
    "loc = []\n",
    "urls = []\n",
    "for feature in data['features']:\n",
    "    mag.append(feature['properties']['mag'])\n",
    "    loc.append(feature['properties']['place'])\n",
    "    urls.append(feature['properties']['url'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "732577fe-f490-45e9-a682-83fc6473a378",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Version 1\n",
    "with open(\"usgs.csv\",\"w\",encoding='utf-8',newline=\"\") as con:\n",
    "    colnames=['magnitude','location','url']\n",
    "    writer = csv.writer(con,delimiter = \",\")\n",
    "    writer.writerow(colnames)\n",
    "    for i in zip(mag,loc,urls):\n",
    "        writer.writerow([i[0],i[1],i[2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "17b8fca2-5549-49fb-ad5e-4fd9677c9d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Version 2\n",
    "with open(\"usgs1.csv\",\"w\",encoding='utf-8',newline=\"\") as con:\n",
    "    colnames=['magnitude','location','url']\n",
    "    writer = csv.writer(con,delimiter = \",\")\n",
    "    writer.writerow(colnames)\n",
    "    for features in data['features']:\n",
    "        m = features['properties']['mag']\n",
    "        l = features['properties']['place']\n",
    "        u = features['properties']['url']\n",
    "        writer.writerow([m,l,u])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c2d9dae6-37d4-440a-8c83-8416f684a60e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Convert this code into dict writer?\n",
    "## Version 1\n",
    "with open(\"usgs3.csv\",\"w\",encoding='utf-8',newline=\"\") as con:\n",
    "    colnames=['magnitude','location','url']\n",
    "    writer = csv.DictWriter(con,fieldnames =colnames)\n",
    "    writer.writeheader()\n",
    "    for i in zip(mag,loc,urls):\n",
    "        writer.writerow({\"magnitude\":i[0],'location':i[1],'url':i[2]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4ba911f5-4e5c-4564-8761-066d802a68ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Version 2\n",
    "with open(\"usgs4.csv\",\"w\",encoding='utf-8',newline=\"\") as con:\n",
    "    colnames=['magnitude','location','url']\n",
    "    writer = csv.DictWriter(con,fieldnames = colnames)\n",
    "    writer.writeheader()\n",
    "    for features in data:\n",
    "        m = features['properties']['mag']\n",
    "        l = features['properties']['place']\n",
    "        u = features['properties']['url']\n",
    "        writer.writerow({\"magnitude\":m,\"location\":l,\"url\":u})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19303b58-126e-4aaa-8a16-fbb92b181b65",
   "metadata": {},
   "source": [
    "### OOPS (Object Oriented Programming)\n",
    "\n",
    "- Create function that can read csv files when the path to the file is given\n",
    "- Create a function that can find the number of rows in the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cf90b896-99e4-46d0-abb9-86dc5eada99f",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../data/file_data.csv\"\n",
    "def read_csv(path):\n",
    "    data = []\n",
    "    with open(path,'r',encoding='utf-8') as con:\n",
    "        reader = csv.reader(con,delimiter = \",\")\n",
    "        for row in reader:\n",
    "            data.append(row)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1617af79-c229-4b46-9b7a-4d3f7602fa72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shape(data):\n",
    "    num_cols = len(data[0])\n",
    "    num_rows = len(data)\n",
    "    return num_rows,num_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "80a0197b-cf1c-4442-b991-d17d181efeea",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "21946ef8-7ec1-475d-a7ff-98a48c0f8284",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(808, 11)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shape(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8368bfb5-b9be-4d90-a897-41bb5dafdac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = \"abc\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e24508f7-e01d-45df-a301-a4e38d073442",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__add__', '__class__', '__contains__', '__delattr__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__getnewargs__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__iter__', '__le__', '__len__', '__lt__', '__mod__', '__mul__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__rmod__', '__rmul__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', 'capitalize', 'casefold', 'center', 'count', 'encode', 'endswith', 'expandtabs', 'find', 'format', 'format_map', 'index', 'isalnum', 'isalpha', 'isascii', 'isdecimal', 'isdigit', 'isidentifier', 'islower', 'isnumeric', 'isprintable', 'isspace', 'istitle', 'isupper', 'join', 'ljust', 'lower', 'lstrip', 'maketrans', 'partition', 'removeprefix', 'removesuffix', 'replace', 'rfind', 'rindex', 'rjust', 'rpartition', 'rsplit', 'rstrip', 'split', 'splitlines', 'startswith', 'strip', 'swapcase', 'title', 'translate', 'upper', 'zfill']\n"
     ]
    }
   ],
   "source": [
    "print(dir(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e1736bb6-0517-4b8b-b18c-869d74207fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "class Reader():\n",
    "    def read_csv(self,path):\n",
    "        data = []\n",
    "        with open(path,\"r\",encoding='utf-8') as con:\n",
    "            reader = csv.reader(con,delimiter = \",\")\n",
    "            for row in reader:\n",
    "                data.append(row)\n",
    "        return data\n",
    "\n",
    "    def read_json(self,path):\n",
    "        with open(path,\"r\",encoding=\"utf-8\") as con:\n",
    "            json_string = con.read()\n",
    "            data = json.loads(json_string)\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4a36eee4-69a4-4bf3-a864-ddee70da5907",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Example of creating an object of the string class\n",
    "a = \"abc\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "968c85e3-fffe-4b77-9b0d-fe9a98e034a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ABC'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "fcc5d1bc-7038-4f13-8a8e-d877ef75eede",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Example of creating an object Reader() class\n",
    "r1 = Reader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "34093f20-921c-48db-8642-4b5c285d4008",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', 'read_csv', 'read_json']\n"
     ]
    }
   ],
   "source": [
    "print(dir(r1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "344a30d9-43e5-4194-923d-df5ddfa78a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_json = \"../data/sample_json.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "3754ea42-ca38-4397-adbb-54ed571b455c",
   "metadata": {},
   "outputs": [],
   "source": [
    "r1 = Reader()\n",
    "r2 = Reader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "bb198433-9597-484e-99dd-d9d98013567c",
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = \"This is string1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "7096c43f-6799-4cbc-9574-d064fdc4b961",
   "metadata": {},
   "outputs": [],
   "source": [
    "s2 = \"this is string2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "14ca7bbb-2365-48e5-8cef-7b90289ea22b",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = \"this is string3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e6b74b04-9b75-4f2d-a26f-254cab52ac8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__add__', '__class__', '__contains__', '__delattr__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__getnewargs__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__iter__', '__le__', '__len__', '__lt__', '__mod__', '__mul__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__rmod__', '__rmul__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', 'capitalize', 'casefold', 'center', 'count', 'encode', 'endswith', 'expandtabs', 'find', 'format', 'format_map', 'index', 'isalnum', 'isalpha', 'isascii', 'isdecimal', 'isdigit', 'isidentifier', 'islower', 'isnumeric', 'isprintable', 'isspace', 'istitle', 'isupper', 'join', 'ljust', 'lower', 'lstrip', 'maketrans', 'partition', 'removeprefix', 'removesuffix', 'replace', 'rfind', 'rindex', 'rjust', 'rpartition', 'rsplit', 'rstrip', 'split', 'splitlines', 'startswith', 'strip', 'swapcase', 'title', 'translate', 'upper', 'zfill']\n"
     ]
    }
   ],
   "source": [
    "print(dir(s1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "7fd95e50-6bba-457b-a787-7b7e9f4676f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__add__', '__class__', '__contains__', '__delattr__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__getnewargs__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__iter__', '__le__', '__len__', '__lt__', '__mod__', '__mul__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__rmod__', '__rmul__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', 'capitalize', 'casefold', 'center', 'count', 'encode', 'endswith', 'expandtabs', 'find', 'format', 'format_map', 'index', 'isalnum', 'isalpha', 'isascii', 'isdecimal', 'isdigit', 'isidentifier', 'islower', 'isnumeric', 'isprintable', 'isspace', 'istitle', 'isupper', 'join', 'ljust', 'lower', 'lstrip', 'maketrans', 'partition', 'removeprefix', 'removesuffix', 'replace', 'rfind', 'rindex', 'rjust', 'rpartition', 'rsplit', 'rstrip', 'split', 'splitlines', 'startswith', 'strip', 'swapcase', 'title', 'translate', 'upper', 'zfill']\n"
     ]
    }
   ],
   "source": [
    "print(dir(s2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "8e62e290-bd0d-4713-b111-29d2da4f06e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Include a function in this class that can give the number of rows in the data\n",
    "class Reader():\n",
    "    \n",
    "    def read(self,path,kind = \"csv\"):\n",
    "        if kind=='csv':\n",
    "            self.read_csv(path)\n",
    "        elif kind =='json':\n",
    "            self.read_json(path)\n",
    "        else:\n",
    "            print(\"Can only read csv or json files\")\n",
    "    \n",
    "    def read_csv(self,path):\n",
    "        d = []\n",
    "        with open(path,\"r\",encoding='utf-8') as con:\n",
    "            reader = csv.reader(con,delimiter = \",\")\n",
    "            for row in reader:\n",
    "                d.append(row)\n",
    "        self.data = d\n",
    "\n",
    "    def read_json(self,path):\n",
    "        with open(path,\"r\",encoding=\"utf-8\") as con:\n",
    "            json_string = con.read()\n",
    "            d = json.loads(json_string)\n",
    "        self.data = d\n",
    "          "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "350d060d-1dc3-496d-ab98-74a229f9b752",
   "metadata": {},
   "source": [
    "- Add a function to this class which is able to create a property called \"shape\" (only the number of rows in csv file or len() in case its a json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "d7c3d637-c593-4e41-a117-ac691b3a44b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Reader():\n",
    "    \n",
    "    def read(self,path,kind = \"csv\"):\n",
    "        if kind=='csv':\n",
    "            self.read_csv(path)\n",
    "        elif kind =='json':\n",
    "            self.read_json(path)\n",
    "        else:\n",
    "            print(\"Can only read csv or json files\")\n",
    "    \n",
    "    def read_csv(self,path):\n",
    "        d = []\n",
    "        with open(path,\"r\",encoding='utf-8') as con:\n",
    "            reader = csv.reader(con,delimiter = \",\")\n",
    "            for row in reader:\n",
    "                d.append(row)\n",
    "        self.data = d\n",
    "        self.shape = len(d)-1\n",
    "\n",
    "    def read_json(self,path):\n",
    "        with open(path,\"r\",encoding=\"utf-8\") as con:\n",
    "            json_string = con.read()\n",
    "            d = json.loads(json_string)\n",
    "        self.data = d\n",
    "        self.shape = len(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "fa7ab3af-a9d1-48b9-868c-32e8035f3647",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "807"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r1 = Reader()\n",
    "r1.read(path,kind='csv')\n",
    "r1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "00fab1f5-b8f5-4581-a273-badca7697b84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2 = Reader()\n",
    "r2.read(path_json,kind='json')\n",
    "r2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0090018-e560-4216-8361-9755c528131b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
