{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6941f63-87be-4a01-b942-c2324babb2f7",
   "metadata": {},
   "source": [
    "## POS tagging and NER\n",
    "- Use spacy to do POS tagging\n",
    "- Case Study to extract product aspects\n",
    "- Use spacy to do NER tagging\n",
    "- Case Study to redact names from emails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8ea4f34-55da-46c3-b507-a59415ff5a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "path = \"./data/samsung.txt\"\n",
    "con=open(path,\"r\",encoding=\"utf-8\")\n",
    "reviews=con.read()\n",
    "review_list=reviews.split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94dd796b-81e7-4a6f-8289-ebba380e568c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46355"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(review_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "60a3315c-a8b0-4cd8-8126-5a2a0c76a384",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I feel so LUCKY to have found this used (phone to us & not used hard at all), phone on line from someone who upgraded and sold this one. My Son liked his old one that finally fell apart after 2.5+ years and didn't want an upgrade!! Thank you Seller, we really appreciate it & your honesty re: said used phone.I recommend this seller very highly & would but from them again!!\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0f4a5018-3fdb-45d7-9f69-411c43011715",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### POS extraction #####\n",
    "import spacy ### pre-trained classifier that can classify pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8112bedf-a604-4442-88b9-f45938094170",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp=spacy.load(\"en_core_web_sm\") ### lemmatization, pos, NER, grammatical parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b87c13c8-904d-4353-b787-85b069a63e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc1=nlp(review_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e2970a2d-676d-4d44-b243-c0c22032b3b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phone\n",
      "phone\n",
      "line\n",
      "one\n",
      "one\n",
      "years\n",
      "upgrade\n",
      "honesty\n",
      "phone\n",
      "seller\n"
     ]
    }
   ],
   "source": [
    "for token in doc1:\n",
    "    if token.pos_==\"NOUN\":\n",
    "        print(token.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "721636bb-8464-4a9e-940d-5ce4884c11ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### 1000 reviews what are the common nouns:\n",
    "nouns=[]\n",
    "for review in review_list[0:100]:\n",
    "    doc=nlp(review)\n",
    "    for token in doc:\n",
    "        if token.pos_==\"NOUN\":\n",
    "            nouns.append(token.lemma_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "818db5e5-c271-452a-94e7-56170735d0c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "phone        107\n",
       "price         12\n",
       "problem       11\n",
       "condition     10\n",
       "seller         9\n",
       "            ... \n",
       "pic            1\n",
       "mode           1\n",
       "host           1\n",
       "iso            1\n",
       "breaking       1\n",
       "Length: 235, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(nouns).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "60ba5c06-8f75-442b-8d69-0ae2bc9c10c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### phone/phones?\n",
    "#### battery/batteries\n",
    "#### root form of a word <===> lemma/lemmatized form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fb394e00-fe36-436c-bbd9-4ce6b2b20553",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I I PRON\n",
      "feel feel VERB\n",
      "so so ADV\n",
      "LUCKY lucky ADJ\n",
      "to to PART\n",
      "have have AUX\n",
      "found find VERB\n",
      "this this DET\n",
      "used use VERB\n",
      "( ( PUNCT\n",
      "phone phone NOUN\n",
      "to to ADP\n",
      "us we PRON\n",
      "& & CCONJ\n",
      "not not PART\n",
      "used use VERB\n",
      "hard hard ADV\n",
      "at at ADV\n",
      "all all ADV\n",
      ") ) PUNCT\n",
      ", , PUNCT\n",
      "phone phone NOUN\n",
      "on on ADP\n",
      "line line NOUN\n",
      "from from ADP\n",
      "someone someone PRON\n",
      "who who PRON\n",
      "upgraded upgrade VERB\n",
      "and and CCONJ\n",
      "sold sell VERB\n",
      "this this DET\n",
      "one one NOUN\n",
      ". . PUNCT\n",
      "My my PRON\n",
      "Son Son PROPN\n",
      "liked like VERB\n",
      "his his PRON\n",
      "old old ADJ\n",
      "one one NOUN\n",
      "that that PRON\n",
      "finally finally ADV\n",
      "fell fall VERB\n",
      "apart apart ADV\n",
      "after after ADP\n",
      "2.5 2.5 NUM\n",
      "+ + NUM\n",
      "years year NOUN\n",
      "and and CCONJ\n",
      "did do AUX\n",
      "n't not PART\n",
      "want want VERB\n",
      "an an DET\n",
      "upgrade upgrade NOUN\n",
      "! ! PUNCT\n",
      "! ! PUNCT\n",
      "Thank thank VERB\n",
      "you you PRON\n",
      "Seller Seller PROPN\n",
      ", , PUNCT\n",
      "we we PRON\n",
      "really really ADV\n",
      "appreciate appreciate VERB\n",
      "it it PRON\n",
      "& & CCONJ\n",
      "your your PRON\n",
      "honesty honesty NOUN\n",
      "re re ADP\n",
      ": : PUNCT\n",
      "said say VERB\n",
      "used used ADJ\n",
      "phone phone NOUN\n",
      ". . PUNCT\n",
      "I I PRON\n",
      "recommend recommend VERB\n",
      "this this DET\n",
      "seller seller NOUN\n",
      "very very ADV\n",
      "highly highly ADV\n",
      "& & CCONJ\n",
      "would would AUX\n",
      "but but CCONJ\n",
      "from from ADP\n",
      "them they PRON\n",
      "again again ADV\n",
      "! ! PUNCT\n",
      "! ! PUNCT\n"
     ]
    }
   ],
   "source": [
    "for token in doc1:\n",
    "    print(token.text,token.lemma_,token.pos_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2504225c-7fe8-49b7-bf22-92543ded21f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "943bac1a-0907-49b2-8ce5-fb6d5d9d7392",
   "metadata": {},
   "outputs": [],
   "source": [
    "### We will make our code mutithreaded\n",
    "### Load relevant models\n",
    "nlp=spacy.load(\"en_core_web_sm\",disable=[\"parser\",\"ner\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3d87c293-9235-4ea9-b2c1-0b45bbaa268c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "46355it [01:02, 740.66it/s] \n"
     ]
    }
   ],
   "source": [
    "nouns=[]\n",
    "for doc in tqdm(nlp.pipe(review_list,batch_size=1,n_process=-1)):\n",
    "    for token in doc:\n",
    "        if token.pos_==\"NOUN\":\n",
    "            nouns.append(token.lemma_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7efb0370-90ca-459b-a450-74590b0285f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "phone        42945\n",
       "battery       4261\n",
       "product       3894\n",
       "screen        3851\n",
       "time          3817\n",
       "             ...  \n",
       "amazed           1\n",
       "simbetter        1\n",
       "telefeno         1\n",
       "soccer           1\n",
       "gun              1\n",
       "Length: 8461, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(nouns).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b6378185-ef9e-4b5e-9c0b-dc8233771deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### What are the things that people mention about the features\n",
    "##### What are the most common words that occur before or after the aspect word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "58698af1-7b3d-4e0e-93f8-0d1e38458329",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f314d4eb-0264-4d2c-89f4-3316332455c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern=re.compile(\"\\w+\\sphone\\s\\w+\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a6951d20-44d1-4720-a6b4-aeaf22e571a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent=\"This phone is awesome\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5c7c9c77-85cd-43f1-b035-a238cd2ec91b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This phone is']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(pattern,sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2ed69020-28aa-4ef2-97b9-d470c19d3391",
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix_suffix=re.findall(pattern,reviews.replace(\"\\n\",\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b6bc758c-5ece-46bf-9d1e-b17b9716b292",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'android phone but'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prefix_suffix[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "54cda4e2-c306-42ac-8d71-15836d293e1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'android'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prefix_suffix[0].split(\" \")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "87250a8b-eb44-43c2-963e-000d39a58af8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'but'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prefix_suffix[0].split(\" \")[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "94f6e23a-f4a7-44d6-8ac0-09f56cd86bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "prefixes=[i.split()[0].lower() for i in prefix_suffix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "73b62af4-1c44-4bc5-9f5f-835b24e3f2f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words=[\"a\",\"about\",\"above\",\"after\",\"again\",\"against\",\"ain\",\"all\",\"am\",\"an\",\"and\",\"any\",\"are\",\"aren\",\n",
    "            \"aren't\",\"as\",\"at\",\"be\",\"because\",\"been\",\"before\",\"being\",\"below\",\"between\",\"both\",\"but\",\"by\",\n",
    "            \"can\",\"couldn\",\"couldn't\",\"d\",\"did\",\"didn\",\"didn't\",\"do\",\"does\",\"doesn\",\"doesn't\",\"doing\",\"don\",\n",
    "            \"don't\",\"down\",\"during\",\"each\",\"few\",\"for\",\"from\",\"further\",\"had\",\"hadn\",\"hadn't\",\"has\",\"hasn\",\n",
    "            \"hasn't\",\"have\",\"haven\",\"haven't\",\"having\",\"he\",\"her\",\"here\",\"hers\",\"herself\",\"him\",\"himself\",\"his\",\n",
    "            \"how\",\"i\",\"if\",\"in\",\"into\",\"is\",\"isn\",\"isn't\",\"it\",\"it's\",\"its\",\"itself\",\"just\",\"ll\",\"m\",\"ma\",\"me\",\n",
    "            \"mightn\",\"mightn't\",\"more\",\"most\",\"mustn\",\"mustn't\",\"my\",\"myself\",\"needn\",\"needn't\",\"no\",\"nor\",\"not\",\n",
    "            \"now\",\"o\",\"of\",\"off\",\"on\",\"once\",\"only\",\"or\",\"other\",\"our\",\"ours\",\"ourselves\",\"out\",\"over\",\"own\",\n",
    "            \"re\",\"s\",\"same\",\"shan\",\"shan't\",\"she\",\"she's\",\"should\",\"should've\",\"shouldn\",\"shouldn't\",\"so\",\"some\",\n",
    "            \"such\",\"t\",\"than\",\"that\",\"that'll\",\"the\",\"their\",\"theirs\",\"them\",\"themselves\",\"then\",\"there\",\"these\",\n",
    "            \"they\",\"this\",\"those\",\"through\",\"to\",\"too\",\"under\",\"until\",\"up\",\"ve\",\"very\",\"was\",\"wasn\",\"wasn't\",\n",
    "            \"we\",\"were\",\"weren\",\"weren't\",\"what\",\"when\",\"where\",\"which\",\"while\",\"who\",\"whom\",\"why\",\"will\",\"with\",\n",
    "            \"won\",\"won't\",\"wouldn\",\"wouldn't\",\"y\",\"you\",\"you'd\",\"you'll\",\"you're\",\"you've\",\"your\",\"yours\",\n",
    "            \"yourself\",\"yourselves\",\"could\",\"he'd\",\"he'll\",\"he's\",\"here's\",\"how's\",\"i'd\",\"i'll\",\"i'm\",\"i've\",\n",
    "            \"let's\",\"ought\",\"she'd\",\"she'll\",\"that's\",\"there's\",\"they'd\",\"they'll\",\"they're\",\"they've\",\"we'd\",\n",
    "            \"we'll\",\"we're\",\"we've\",\"what's\",\"when's\",\"where's\",\"who's\",\"why's\",\"would\",\"able\",\"abst\",\n",
    "            \"accordance\",\"according\",\"accordingly\",\"across\",\"act\",\"actually\",\"added\",\"adj\",\"affected\",\"affecting\",\"affects\",\"afterwards\",\"ah\",\n",
    "            \"almost\",\"alone\",\"along\",\"already\",\"also\",\"although\",\"always\",\"among\",\"amongst\",\"announce\",\"another\",\"anybody\",\"anyhow\",\"anymore\",\n",
    "            \"anyone\",\"anything\",\"anyway\",\"anyways\",\"anywhere\",\"apparently\",\"approximately\",\"arent\",\"arise\",\"around\",\"aside\",\"ask\",\"asking\",\"auth\",\n",
    "            \"available\",\"away\",\"awfully\",\"b\",\"back\",\"became\",\"become\",\"becomes\",\"becoming\",\"beforehand\",\"begin\",\"beginning\",\"beginnings\",\"begins\",\n",
    "            \"behind\",\"believe\",\"beside\",\"besides\",\"beyond\",\"biol\",\"brief\",\"briefly\",\"c\",\"ca\",\"came\",\"cannot\",\"can't\",\"cause\",\"causes\",\"certain\",\n",
    "            \"certainly\",\"co\",\"com\",\"come\",\"comes\",\"contain\",\"containing\",\"contains\",\"couldnt\",\"date\",\"different\",\"done\",\"downwards\",\"due\",\"e\",\"ed\",\n",
    "            \"edu\",\"effect\",\"eg\",\"eight\",\"eighty\",\"either\",\"else\",\"elsewhere\",\"end\",\"ending\",\"enough\",\"especially\",\"et\",\"etc\",\"even\",\"ever\",\"every\",\n",
    "            \"everybody\",\"everyone\",\"everything\",\"everywhere\",\"ex\",\"except\",\"f\",\"far\",\"ff\",\"fifth\",\"first\",\"five\",\"fix\",\"followed\",\"following\",\n",
    "            \"follows\",\"former\",\"formerly\",\"forth\",\"found\",\"four\",\"furthermore\",\"g\",\"gave\",\"get\",\"gets\",\"getting\",\"give\",\"given\",\"gives\",\"giving\",\n",
    "            \"go\",\"goes\",\"gone\",\"got\",\"gotten\",\"h\",\"happens\",\"hardly\",\"hed\",\"hence\",\"hereafter\",\"hereby\",\"herein\",\"heres\",\"hereupon\",\"hes\",\"hi\",\n",
    "            \"hid\",\"hither\",\"home\",\"howbeit\",\"however\",\"hundred\",\"id\",\"ie\",\"im\",\"immediate\",\"immediately\",\"importance\",\"important\",\"inc\",\"indeed\",\n",
    "            \"index\",\"information\",\"instead\",\"invention\",\"inward\",\"itd\",\"it'll\",\"j\",\"k\",\"keep\",\"keeps\",\"kept\",\"kg\",\"km\",\"know\",\"known\",\"knows\",\"l\",\n",
    "            \"largely\",\"last\",\"lately\",\"later\",\"latter\",\"latterly\",\"least\",\"less\",\"lest\",\"let\",\"lets\",\"like\",\"liked\",\"likely\",\"line\",\"little\",\"'ll\",\n",
    "            \"look\",\"looking\",\"looks\",\"ltd\",\"made\",\"mainly\",\"make\",\"makes\",\"many\",\"may\",\"maybe\",\"mean\",\"means\",\"meantime\",\"meanwhile\",\"merely\",\"mg\",\n",
    "            \"might\",\"million\",\"miss\",\"ml\",\"moreover\",\"mostly\",\"mr\",\"mrs\",\"much\",\"mug\",\"must\",\"n\",\"na\",\"name\",\"namely\",\"nay\",\"nd\",\"near\",\"nearly\",\n",
    "            \"necessarily\",\"necessary\",\"need\",\"needs\",\"neither\",\"never\",\"nevertheless\",\"new\",\"next\",\"nine\",\"ninety\",\"nobody\",\"non\",\"none\",\n",
    "            \"nonetheless\",\"noone\",\"normally\",\"nos\",\"noted\",\"nothing\",\"nowhere\",\"obtain\",\"obtained\",\"obviously\",\"often\",\"oh\",\"ok\",\"okay\",\"old\",\n",
    "            \"omitted\",\"one\",\"ones\",\"onto\",\"ord\",\"others\",\"otherwise\",\"outside\",\"overall\",\"owing\",\"p\",\"page\",\"pages\",\"part\",\"particular\",\n",
    "            \"particularly\",\"past\",\"per\",\"perhaps\",\"placed\",\"please\",\"plus\",\"poorly\",\"possible\",\"possibly\",\"potentially\",\"pp\",\"predominantly\",\n",
    "            \"present\",\"previously\",\"primarily\",\"probably\",\"promptly\",\"proud\",\"provides\",\"put\",\"q\",\"que\",\"quickly\",\"quite\",\"qv\",\"r\",\"ran\",\"rather\",\n",
    "            \"rd\",\"readily\",\"really\",\"recent\",\"recently\",\"ref\",\"refs\",\"regarding\",\"regardless\",\"regards\",\"related\",\"relatively\",\"research\",\n",
    "            \"respectively\",\"resulted\",\"resulting\",\"results\",\"right\",\"run\",\"said\",\"saw\",\"say\",\"saying\",\"says\",\"sec\",\"section\",\"see\",\"seeing\",\n",
    "            \"seem\",\"seemed\",\"seeming\",\"seems\",\"seen\",\"self\",\"selves\",\"sent\",\"seven\",\"several\",\"shall\",\"shed\",\"shes\",\"show\",\"showed\",\"shown\",\"showns\",\"shows\",\"significant\",\"significantly\",\"similar\",\"similarly\",\"since\",\"six\",\"slightly\",\"somebody\",\"somehow\",\"someone\",\"somethan\",\"something\",\"sometime\",\"sometimes\",\"somewhat\",\"somewhere\",\"soon\",\"sorry\",\"specifically\",\"specified\",\"specify\",\"specifying\",\"still\",\"stop\",\"strongly\",\"sub\",\"substantially\",\"successfully\",\"sufficiently\",\"suggest\",\"sup\",\"sure\",\"take\",\"taken\",\"taking\",\"tell\",\"tends\",\"th\",\"thank\",\"thanks\",\"thanx\",\"thats\",\"that've\",\"thence\",\"thereafter\",\"thereby\",\"thered\",\"therefore\",\"therein\",\"there'll\",\"thereof\",\"therere\",\"theres\",\"thereto\",\"thereupon\",\"there've\",\"theyd\",\"theyre\",\"think\",\"thou\",\"though\",\"thoughh\",\"thousand\",\"throug\",\"throughout\",\"thru\",\"thus\",\"til\",\"tip\",\"together\",\"took\",\"toward\",\"towards\",\"tried\",\"tries\",\"truly\",\"try\",\"trying\",\"ts\",\"twice\",\"two\",\"u\",\"un\",\"unfortunately\",\"unless\",\"unlike\",\"unlikely\",\"unto\",\"upon\",\"ups\",\"us\",\"use\",\"used\",\"useful\",\"usefully\",\"usefulness\",\"uses\",\"using\",\"usually\",\"v\",\"value\",\"various\",\"'ve\",\"via\",\"viz\",\"vol\",\"vols\",\"vs\",\"w\",\"want\",\"wants\",\"wasnt\",\"way\",\"wed\",\"welcome\",\"went\",\"werent\",\"whatever\",\"what'll\",\"whats\",\"whence\",\"whenever\",\"whereafter\",\"whereas\",\"whereby\",\"wherein\",\"wheres\",\"whereupon\",\"wherever\",\"whether\",\"whim\",\"whither\",\"whod\",\"whoever\",\"whole\",\"who'll\",\"whomever\",\"whos\",\"whose\",\"widely\",\"willing\",\"wish\",\"within\",\"without\",\"wont\",\"words\",\"world\",\"wouldnt\",\"www\",\"x\",\"yes\",\"yet\",\"youd\",\"youre\",\"z\",\"zero\",\"a's\",\"ain't\",\"allow\",\"allows\",\"apart\",\"appear\",\"appreciate\",\"appropriate\",\"associated\",\"best\",\"better\",\"c'mon\",\"c's\",\"cant\",\"changes\",\"clearly\",\"concerning\",\"consequently\",\"consider\",\"considering\",\"corresponding\",\"course\",\"currently\",\"definitely\",\"described\",\"despite\",\"entirely\",\"exactly\",\"example\",\"going\",\"greetings\",\"hello\",\"help\",\"hopefully\",\"ignored\",\"inasmuch\",\"indicate\",\"indicated\",\"indicates\",\"inner\",\"insofar\",\"it'd\",\"keep\",\"keeps\",\"novel\",\"presumably\",\"reasonably\",\"second\",\"secondly\",\"sensible\",\"serious\",\"seriously\",\"sure\",\"t's\",\"third\",\"thorough\",\"thoroughly\",\"three\",\"well\",\"wonder\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4a066424-802b-4a9c-aa13-00dabf45e570",
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix=[word for word in prefixes if not word in stop_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0d603552-26bd-4897-b848-edab980ab722",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "great       1368\n",
       "good         655\n",
       "cell         485\n",
       "smart        352\n",
       "nice         334\n",
       "            ... \n",
       "largest        1\n",
       "rubber         1\n",
       "mail           1\n",
       "minutes        1\n",
       "outgoing       1\n",
       "Length: 593, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(prefix).value_counts() ## common words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b15a8279-ff3e-4466-a439-c4914952b9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prefixes(keyword):\n",
    "    pattern=re.compile(r\"\\w+\\s{}\\s\\w+\".format(keyword))\n",
    "    prefix_suffix=re.findall(pattern,reviews.replace(\"\\n\",\" \"))\n",
    "    prefixes=[i.split()[0].lower() for i in prefix_suffix]\n",
    "    prefix=[word for word in prefixes if not word in stop_words]\n",
    "    prefix=pd.Series(prefix).value_counts().head(5).index\n",
    "    result=pd.DataFrame({'prefix':prefix})\n",
    "    result['keyword']=keyword\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6c49eabb-7afe-4623-be2d-44989126b20a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prefix</th>\n",
       "      <th>keyword</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>touch</td>\n",
       "      <td>screen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>big</td>\n",
       "      <td>screen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>great</td>\n",
       "      <td>screen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>large</td>\n",
       "      <td>screen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bigger</td>\n",
       "      <td>screen</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   prefix keyword\n",
       "0   touch  screen\n",
       "1     big  screen\n",
       "2   great  screen\n",
       "3   large  screen\n",
       "4  bigger  screen"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_prefixes(\"screen\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "95ab3548-9183-4b02-98c6-ea6120011f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_suffixes(keyword):\n",
    "    pattern=re.compile(r\"\\w+\\s{}\\s\\w+\".format(keyword))\n",
    "    prefix_suffix=re.findall(pattern,reviews.replace(\"\\n\",\" \"))\n",
    "    suffixes=[i.split()[-1].lower() for i in prefix_suffix]\n",
    "    suffix=[word for word in suffixes if not word in stop_words]\n",
    "    suffix=pd.Series(suffix).value_counts().head(5).index\n",
    "    result=pd.DataFrame({'suffix':suffix})\n",
    "    result['keyword']=keyword\n",
    "    result=result[['keyword','suffix']]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "57b401ce-a1a0-41d6-a9b9-caedbeb41a70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keyword</th>\n",
       "      <th>suffix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>battery</td>\n",
       "      <td>life</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>battery</td>\n",
       "      <td>lasts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>battery</td>\n",
       "      <td>runs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>battery</td>\n",
       "      <td>drains</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>battery</td>\n",
       "      <td>charge</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   keyword  suffix\n",
       "0  battery    life\n",
       "1  battery   lasts\n",
       "2  battery    runs\n",
       "3  battery  drains\n",
       "4  battery  charge"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_suffixes(\"battery\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c46e80f9-4a17-4b63-b707-a26d06401dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "### NER tagging\n",
    "nlp=spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(\"Apple is looking at buying U.K. startup for $1 billion\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f58b2446-2161-4eb0-92c0-f202a4dabbb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple 0 5 ORG\n",
      "U.K. 27 31 GPE\n",
      "$1 billion 44 54 MONEY\n"
     ]
    }
   ],
   "source": [
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.start_char, ent.end_char, ent.label_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef44162c-bcd3-4083-82d8-971484bfb4e1",
   "metadata": {},
   "source": [
    "Data [link](https://drive.google.com/file/d/1oGoJrXYcBrNkAvWXmDkwtHJkZTAFb5lN/view?usp=sharing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8188bd52-e2a8-4938-bf23-3b9919b973e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/data/4625.txt','r') as reader:\n",
    "    text = reader.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2f5c63a7-fbb3-4c62-94da-657ec32db761",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Karen,\n",
      "\n",
      "Thank you for the update.  It looks like we'll plan on having the EBS/Avaya \n",
      "meetings on January 10th and 11th, 2001.  The first day will be a full day, \n",
      "the second will be 1/2 day, a.m. session.  You have asked me to provide a \n",
      "list of Enron attendees, titles, which day(s) they would likely attend, and \n",
      "some background information on the meeting(s) purposes.  An explanation of \n",
      "the meetings' proposed focus and probable attendees is in the attached \n",
      "meeting notes.  \n",
      "\n",
      "The notes are from the November meeting which we coordinated and held for \n",
      "Enron Broadband Services and Dave Johnson.  By copy of this note to Kim \n",
      "Godfrey, we'll update the EBS executives on the meetings, and work on \n",
      "arranging their calendar availability.  So far, we have had the EBS execs' \n",
      "calendars penciled in for the time slot of January 9-11.  At this point, I \n",
      "would expect that the EBS attendee list would look something like this:  \n",
      "\n",
      "Jim Crowder, VP, Enterprise Services; Enron Broadband Services - day 2 \n",
      "Everett Plante, VP and CIO, Enron Broadband Services - day 2\n",
      "Larry Ciscon, VP Software Architecture, EBS - day 1&2\n",
      "  (selected team members of Larry's organization - individuals TBD by Larry) \n",
      "- day 1  \n",
      "Steve Pearlman, VP, Strategic Development, EBS - day 2 and/or day 1\n",
      "Kim Godfrey, Director, East Origination, EBS - day 1&2  \n",
      "Jeff Youngflesh, Director, Business Development, Enron Global Strategic \n",
      "Sourcing - day 1&2  \n",
      "    (others as suggested by Kim Godfrey or other EBS executive)\n",
      "\n",
      "From Avaya, the EBS team would like to meet with Dave Johnson, Serge \n",
      "Minassian, John Stephenson, and their selected Avaya team members.  \n",
      "\n",
      "Per my conversation with you earlier today, the Enron Broadband Services \n",
      "meetings w/Avaya will need to be scheduled such that the overall agenda will \n",
      "\"flip-flop\" day 1 with day 2.  Originally, the first day was going to be a \n",
      "half-day executive strategizing meeting in the p.m. (allowing for travel to \n",
      "NJ), and the 2nd day to be more a product- or solutions-focused effort, with \n",
      "a full day's agenda.  Based on the fact that Dave Johnson will only be \n",
      "available the morning of the 11th, the meeting schedule will be reversed, \n",
      "such that the \"full day/products/solutions\" meetings will precede the \n",
      "half-day executive strategy sessions.  I have checked w/Barbara Korp, and \n",
      "Serge Minassian and John Stephenson are both available on the 11th, as well \n",
      "(John Stephenson would have a hard stop at 10:30).\n",
      "\n",
      "\n",
      "Thank you,\n",
      "\n",
      "Jeff Youngflesh\n",
      "713-345-5968\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- Forwarded by Jeff Youngflesh/NA/Enron on 12/11/2000 01:29 PM -----\n",
      "\n",
      "\t\"Oswald, Karen R (Karen)\" <kroswald@avaya.com>\n",
      "\t12/11/2000 11:32 AM\n",
      "\t\t \n",
      "\t\t To: jeff.youngflesh@enron.com\n",
      "\t\t cc: \n",
      "\t\t Subject: Preliminary dates\n",
      "\n",
      "Jeff,\n",
      "\n",
      "So far these are the dates that associates in New Jersey are available -\n",
      "January 10 (full day) and January 11 (half day).\n",
      "\n",
      "Dave Johnson is only available on Thursday, January 11 in the morning.\n",
      "\n",
      "Please send the agenda and the list of participants so that I can forward\n",
      "that to Dave's office.\n",
      "\n",
      "Thank you,\n",
      "\n",
      "Karen Oswald\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "202f4bd6-17b6-42cc-af03-f286c03e45e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1e6cb9bb-8477-4cef-bdba-5c2ed5143eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "start,end,instances = [],[],[]\n",
    "for ent in doc.ents:\n",
    "    #print(ent.text, ent.start_char, ent.end_char, ent.label_)\n",
    "    if ent.label_=='PERSON':\n",
    "        start.append(ent.start_char)\n",
    "        end.append(ent.end_char)\n",
    "        instances.append(ent.text)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2ebabfdc-8cd6-4f1d-9266-380c6e8c8a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for instance in instances:\n",
    "    text = text.replace(instance,\"<redacted>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "93fbd2ec-f599-425b-bcf3-414cf0cbd9aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<redacted>,\n",
      "\n",
      "Thank you for the update.  It looks like we'll plan on having the EBS/Avaya \n",
      "meetings on January 10th and 11th, 2001.  The first day will be a full day, \n",
      "the second will be 1/2 day, a.m. session.  You have asked me to provide a \n",
      "list of Enron attendees, titles, which day(s) they would likely attend, and \n",
      "some background information on the meeting(s) purposes.  An explanation of \n",
      "the meetings' proposed focus and probable attendees is in the attached \n",
      "meeting notes.  \n",
      "\n",
      "The notes are from the November meeting which we coordinated and held for \n",
      "Enron Broadband Services and <redacted>.  By copy of this note to <redacted>, we'll update the EBS executives on the meetings, and work on \n",
      "arranging their calendar availability.  So far, we have had the EBS execs' \n",
      "calendars penciled in for the time slot of January 9-11.  At this point, I \n",
      "would expect that the EBS attendee list would look something like this:  \n",
      "\n",
      "<redacted>, VP, Enterprise Services; Enron Broadband Services - day 2 \n",
      "<redacted>, VP and CIO, Enron Broadband Services - day 2\n",
      "<redacted>, VP Software Architecture, EBS - day 1&2\n",
      "  (selected team members of <redacted>'s organization - individuals TBD by <redacted>) \n",
      "- day 1  \n",
      "<redacted>, VP, Strategic Development, EBS - day 2 and/or day 1\n",
      "<redacted>, Director, East Origination, EBS - day 1&2  \n",
      "<redacted>, Director, Business Development, Enron Global Strategic \n",
      "Sourcing - day 1&2  \n",
      "    (others as suggested by <redacted> or other EBS executive)\n",
      "\n",
      "From Avaya, the EBS team would like to meet with <redacted>, <redacted>, <redacted>, and their selected Avaya team members.  \n",
      "\n",
      "Per my conversation with you earlier today, the Enron Broadband Services \n",
      "meetings w/Avaya will need to be scheduled such that the overall agenda will \n",
      "\"flip-flop\" day 1 with day 2.  Originally, the first day was going to be a \n",
      "half-day executive strategizing meeting in the p.m. (allowing for travel to \n",
      "NJ), and the 2nd day to be more a product- or solutions-focused effort, with \n",
      "a full day's agenda.  Based on the fact that <redacted> will only be \n",
      "available the morning of the 11th, the meeting schedule will be reversed, \n",
      "such that the \"full day/products/solutions\" meetings will precede the \n",
      "half-day executive strategy sessions.  I have checked w/<redacted>, and \n",
      "<redacted> and <redacted> are both available on the 11th, as well \n",
      "(<redacted> would have a hard stop at 10:30).\n",
      "\n",
      "\n",
      "Thank you,\n",
      "\n",
      "<redacted>\n",
      "713-345-5968\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----- Forwarded by <redacted>/NA/Enron on 12/11/2000 01:29 PM -----\n",
      "\n",
      "\t\"<redacted>, <redacted> R (<redacted>)\" <kroswald@avaya.com>\n",
      "\t12/11/2000 11:32 AM\n",
      "\t\t \n",
      "\t\t To: jeff.youngflesh@enron.com\n",
      "\t\t cc: \n",
      "\t\t Subject: Preliminary dates\n",
      "\n",
      "<redacted>,\n",
      "\n",
      "So far these are the dates that associates in New Jersey are available -\n",
      "January 10 (full day) and January 11 (half day).\n",
      "\n",
      "<redacted> is only available on Thursday, January 11 in the morning.\n",
      "\n",
      "Please send the agenda and the list of participants so that I can forward\n",
      "that to <redacted>'s office.\n",
      "\n",
      "Thank you,\n",
      "\n",
      "<redacted> <redacted>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c40f006-6399-41ef-b619-ffe382982b23",
   "metadata": {},
   "source": [
    "### Topic Modelling NMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "bd648cdb-363f-455e-9f59-10fa48d09249",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I feel so LUCKY to have found this used (phone to us & not used hard at all), phone on line from someone who upgraded and sold this one. My Son liked his old one that finally fell apart after 2.5+ years and didn't want an upgrade!! Thank you Seller, we really appreciate it & your honesty re: said used phone.I recommend this seller very highly & would but from them again!!\""
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6705cee3-c492-48d3-bab4-7be2675061c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████| 46355/46355 [05:34<00:00, 138.46it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "processed_reviews=[]\n",
    "for review in tqdm(review_list):\n",
    "    doc=nlp(review)\n",
    "    one_review=[]\n",
    "    for word in doc:\n",
    "        if word.lemma_!='-PRON-':\n",
    "            one_review.append(word.lemma_)\n",
    "    review_processed=\" \".join(one_review)\n",
    "    processed_reviews.append(review_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ad663b95-2682-471d-9806-f2ef94d47b4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(46355, 15942)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### create a tfidf representation \n",
    "from sklearn.feature_extraction import text\n",
    "tfidf=text.TfidfVectorizer(input = processed_reviews,stop_words='english')\n",
    "tfidf_matrix=tfidf.fit_transform(processed_reviews)\n",
    "tfidf_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "fe7d62f1-5b4a-4430-ba8c-679354ac235d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import NMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "4433e4e0-860c-4077-bbff-9d0c19f9c519",
   "metadata": {},
   "outputs": [],
   "source": [
    "mod=NMF(n_components=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "06fb7f45-12b3-4506-be36-bb0a5ddd3b6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gunnvantsaini/miniforge3/lib/python3.9/site-packages/sklearn/decomposition/_nmf.py:289: FutureWarning: The 'init' value, when 'init=None' and n_components is less than n_samples and n_features, will be changed from 'nndsvd' to 'nndsvda' in 1.1 (renaming of 0.26).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 860 ms, sys: 590 ms, total: 1.45 s\n",
      "Wall time: 371 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "A=mod.fit_transform(tfidf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c094e99c-0bba-4eef-802b-0b6e018219f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(46355, 4)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.shape ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "65d6dfc6-5f1c-46bb-9bb3-d9a64d5f4f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "B=mod.components_###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "3f317e0d-87f6-4708-a1da-9539850a4280",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 15942)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "af43fd67-1417-47e3-980b-9f25d776dbb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['phone' 'product' 'price' 'work' 'far']\n",
      "['phone' 'work' 'price' 'product' 'use']\n",
      "['product' 'recommend' 'thank' 'phone' 'seller']\n",
      "['phone' 'new' 'perfect' 'buy' 'use']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "tokens=np.array(tfidf.get_feature_names_out())\n",
    "for row in B:\n",
    "    idx=row.argsort()[-6:-1][::-1]\n",
    "    print(tokens[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "3ab381a2-e4e7-41c1-9d49-1ea0364a4cfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████| 46355/46355 [02:24<00:00, 320.54it/s]\n"
     ]
    }
   ],
   "source": [
    "### Lets extract nouns ###\n",
    "from tqdm import tqdm\n",
    "processed_reviews=[]\n",
    "nlp=spacy.load(\"en_core_web_sm\",disable=[\"parser\",\"ner\"])\n",
    "for review in tqdm(review_list):\n",
    "    doc=nlp(review)\n",
    "    one_review=[]\n",
    "    for word in doc:\n",
    "        if word.pos_=='NOUN':\n",
    "            one_review.append(word.lemma_)\n",
    "    review_processed=\" \".join(one_review)\n",
    "    processed_reviews.append(review_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "cb4f8f36-084b-4dfc-9528-15139592bc1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'phone phone line one one year upgrade honesty phone seller'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_reviews[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "417772c2-f6bb-4679-8205-c6b2da8125e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### What topics we can see if we use only nouns ####\n",
    "tfidf=text.TfidfVectorizer(input=processed_reviews,stop_words='english')\n",
    "tfidf_matrix=tfidf.fit_transform(processed_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "0fb0aa74-c605-4b64-a6bd-eb3fce06200a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mod=NMF(n_components=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "41151123-0198-4be8-b9c5-3f43ca3728ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 459 ms, sys: 325 ms, total: 785 ms\n",
      "Wall time: 153 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gunnvantsaini/miniforge3/lib/python3.9/site-packages/sklearn/decomposition/_nmf.py:289: FutureWarning: The 'init' value, when 'init=None' and n_components is less than n_samples and n_features, will be changed from 'nndsvd' to 'nndsvda' in 1.1 (renaming of 0.26).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "A=mod.fit_transform(tfidf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "0c437143-cf23-43fa-b3c8-25ffc4ff39ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(46355, 4)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.shape ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "42cefbc8-0703-4abc-bb2d-6b99a956a19b",
   "metadata": {},
   "outputs": [],
   "source": [
    "B=mod.components_###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "c2b5a73e-0a78-4b49-92f0-0e8253e2247a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 7479)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "1714399e-7865-49c7-b15e-86f3b69f1035",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['price' 'problem' 'time' 'battery' 'screen']\n",
      "['time' 'seller' 'price' 'service' 'quality']\n",
      "['producto' 'celular' 'recomendado' 'fono' 'price']\n",
      "['thank' 'condition' 'cellphone' 'seller' 'work']\n"
     ]
    }
   ],
   "source": [
    "tokens=np.array(tfidf.get_feature_names_out())\n",
    "for row in B:\n",
    "    idx=row.argsort()[-6:-1][::-1]\n",
    "    print(tokens[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c0e9e3-e33c-4d95-838d-3d82f8e29d07",
   "metadata": {},
   "source": [
    "![](regex.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a97be5-0323-4671-b2be-50351acc53c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
