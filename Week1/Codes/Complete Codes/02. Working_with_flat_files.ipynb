{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b06fccf3-b264-497d-a0ab-f0e25ee2d547",
   "metadata": {},
   "source": [
    "----\n",
    "**Author**: Gunnvant\n",
    "\n",
    "**Description**: Working with flat files\n",
    "\n",
    "**Audience**: Beginner\n",
    "\n",
    "**Pre-requitisites**: Python 101\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## TOC\n",
    "- Using open() to manipulate text files is not very scalable\n",
    "- csv reader: Read and easily manipulate flat files\n",
    "- json reader: Read and manipulate json files\n",
    "\n",
    "\n",
    "A couple of previous examples that we saw where the `open()` directive was used to handle text files. We saw that reading a row was usually not a very trivial excercise. Recall the class problem on twitter dataset, the following piece of code was written:\n",
    "\n",
    "```python\n",
    "day = '26'\n",
    "cnt = 0\n",
    "for tweet in tweets_list[1:]:\n",
    "    date = tweet.split(\"|\")[0] ###-> This split is not trivial, one has to know the delimiter, also here finding the date value in a row is again a little painful one has to know the position of columns in the table/dataset\n",
    "    date = date.replace('\"',\"\")\n",
    "    if date.startswith(date_mapping[day]):\n",
    "        cnt+=1\n",
    "```\n",
    "\n",
    "A lot of the unnecessary details are handled by a python module called [`csv`](https://docs.python.org/3/library/csv.html). We will use this module to see how it can make our life easy. Also if you do appear for data engineering interviews or even data science interviews you can expect first principle questions on your ability to work with simple flat files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "788f92e5-2475-455f-9e30-3d1da68f5e64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Tweet_Date', 'Tweet_Text', 'Tweet_Handle']\n",
      "['Thu Dec 26 123415 0000 2013', 'ashdubey ratigirl FirstpostBiz First economic move by AamAadmiParty  How come it has gone down in Guj', 'maverickenator']\n",
      "['Thu Dec 26 123413 0000 2013', 'RT anandpassion Growing popularity can seen as AAP websites Rank 275 in India highest ever for a political party JoinAAP ankitlal Aam', 'aapkask']\n",
      "['Thu Dec 26 123402 0000 2013', 'RT anandpassion Growing popularity can seen as AAP websites Rank 275 in India highest ever for a political party JoinAAP ankitlal Aam', 'arpshalder']\n",
      "['Thu Dec 26 123354 0000 2013', 'ArvindKejriwal AapYogendra AamAadmiParty I hope your party realizes why the likes of alkalamba are trying to join AAP now Be careful', 'GargaC']\n",
      "['Thu Dec 26 123351 0000 2013', 'RT ssttuuttii Press Conference AamAadmiParty Application form for candidature for LS2014 is being uploaded at website AAP4India http', 'kejriwalfanclub']\n",
      "['Thu Dec 26 123346 0000 2013', 'anandpassion AamAadmiParty ankitlal Why Dont u ppl put Advertisement on ur website after showing these numbersno NEED of Donations LOL', 'varaliprasoon']\n",
      "['Thu Dec 26 123343 0000 2013', 'ChaloDelhi SatyaPrakashDu5 AamAadmiParty ThanksWhat is the address of AAP Jamshedpur Unit of AAP', 'SharanVikash']\n",
      "['Thu Dec 26 123341 0000 2013', 'Outlookindia When will Home Min probe financing of other political parties AamAadmiParty ArvindKejriwal', 'gauravlavania']\n",
      "['Thu Dec 26 123333 0000 2013', 'RT anandpassion Growing popularity can seen as AAP websites Rank 275 in India highest ever for a political party JoinAAP ankitlal Aam', 'Sholoana1']\n"
     ]
    }
   ],
   "source": [
    "import csv \n",
    "cnt = 0\n",
    "with open(\"../../data/tweets_assignment.txt\",\"r\") as f:\n",
    "    reader = csv.reader(f,delimiter=\"|\")\n",
    "    for row in reader: ## there was no need to do an explicit split based on |\n",
    "        print(row) ## The quoted text seems to have been automatically handled\n",
    "        cnt+=1\n",
    "        if cnt==10:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29f3594d-930e-485e-a280-d791158ac9cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "## Lets see if the csv reader also handles the quoted characters\n",
    "cnt = 0\n",
    "with open(\"../../data/tweets_assignment.txt\",\"r\") as f:\n",
    "    reader = csv.reader(f,delimiter = \"|\")\n",
    "    for row in reader:\n",
    "        print(row[0].startswith(\"Thu Dec 26\")) ## This confirms that the csv module will automatically take care of many details for us\n",
    "        cnt+=1\n",
    "        if cnt==12:\n",
    "            break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ceb22c25-48e1-495f-8f95-1fa0d48bb37b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Dec 26 123415 0000 2013\n",
      "Thu Dec 26 123413 0000 2013\n",
      "Thu Dec 26 123402 0000 2013\n",
      "Thu Dec 26 123354 0000 2013\n",
      "Thu Dec 26 123351 0000 2013\n",
      "Thu Dec 26 123346 0000 2013\n",
      "Thu Dec 26 123343 0000 2013\n",
      "Thu Dec 26 123341 0000 2013\n",
      "Thu Dec 26 123333 0000 2013\n",
      "Thu Dec 26 123328 0000 2013\n"
     ]
    }
   ],
   "source": [
    "## There is another reader called dictreader\n",
    "cnt = 0\n",
    "with open(\"../../data/tweets_assignment.txt\",\"r\") as f:\n",
    "    reader = csv.DictReader(f,delimiter=\"|\")\n",
    "    for row in reader:\n",
    "        print(row['Tweet_Date']) ## this is now even simpler as column values can be accessed as dictionay key-value pairs\n",
    "        cnt+=1\n",
    "        if cnt==10:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c5d91768-90aa-462b-85d0-9f0894816ba6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "cnt = 0\n",
    "with open(\"../../data/tweets_assignment.txt\",\"r\") as f:\n",
    "    reader = csv.DictReader(f,delimiter=\"|\")\n",
    "    for row in reader:\n",
    "        print(row['Tweet_Date'].startswith(\"Thu Dec 26\"))\n",
    "        cnt+=1\n",
    "        if cnt==10:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5108825c-9bd3-4243-93aa-1c693a847e41",
   "metadata": {},
   "source": [
    "### Class Excercise (writer and DictWriter)\n",
    "\n",
    "Use the tweets_assignment.txt to find out how many tweets were posted on 23, 24, 25, 26 December. Write the results in a csv file using the writer or DictWriter class. The file should follow the following format:\n",
    "\n",
    "```csv\n",
    "count_23,count_24,count_25,count_26\n",
    "val1,val2,val3,val4\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b166e6-434a-4994-b1c3-e854d50daa4d",
   "metadata": {},
   "source": [
    "## JSON Data\n",
    "\n",
    "Another very popular format for data is the json data. This is nowadays the prefered way of transfering data over web applications. As a data analyst, data scientist or a data engineer you will encounter this form of data more often than not. We will use the dataset named `sample_json.json` to see what is the general structure of json data. Use this [link](http://jsonviewer.stack.hu/) to understand the `sample_json.json` better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "49e5e180-e40a-4925-8728-17e61acf8a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"../../data/sample_json.json\",\"r\",encoding=\"utf-8\") as f:\n",
    "    data = json.loads(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "62ef28a2-d036-450b-8075-1a1282bc38a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['type', 'metadata', 'features', 'bbox'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "db85358c-c9a3-498d-a1be-a712d1fb04b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'type': 'Feature',\n",
       " 'properties': {'mag': 2.1500001,\n",
       "  'place': '3 km ENE of Pāhala, Hawaii',\n",
       "  'time': 1626859250480,\n",
       "  'updated': 1626859447300,\n",
       "  'tz': None,\n",
       "  'url': 'https://earthquake.usgs.gov/earthquakes/eventpage/hv72595567',\n",
       "  'detail': 'https://earthquake.usgs.gov/earthquakes/feed/v1.0/detail/hv72595567.geojson',\n",
       "  'felt': None,\n",
       "  'cdi': None,\n",
       "  'mmi': None,\n",
       "  'alert': None,\n",
       "  'status': 'automatic',\n",
       "  'tsunami': 0,\n",
       "  'sig': 71,\n",
       "  'net': 'hv',\n",
       "  'code': '72595567',\n",
       "  'ids': ',hv72595567,',\n",
       "  'sources': ',hv,',\n",
       "  'types': ',origin,phase-data,',\n",
       "  'nst': 44,\n",
       "  'dmin': None,\n",
       "  'rms': 0.100000001,\n",
       "  'gap': 113,\n",
       "  'magType': 'md',\n",
       "  'type': 'earthquake',\n",
       "  'title': 'M 2.2 - 3 km ENE of Pāhala, Hawaii'},\n",
       " 'geometry': {'type': 'Point',\n",
       "  'coordinates': [-155.451171875, 19.2175006866455, 35.3600006103516]},\n",
       " 'id': 'hv72595567'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['features'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d829cce4-fe97-4f3f-bd0b-d0af946e27a3",
   "metadata": {},
   "source": [
    "## Class Excercise:\n",
    "\n",
    "Extract the information about each earthquake event's:\n",
    "\n",
    "1. Magnitude \n",
    "2. Location\n",
    "3. Url\n",
    "\n",
    "Create three lists with information on the three parameters listed above. Then write this information in a csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b75ac8fc-ea42-4b8a-857c-151a28049982",
   "metadata": {},
   "outputs": [],
   "source": [
    "magnitude = [f['properties']['mag'] for f in data['features']]\n",
    "location = [f['properties']['place'] for f in data['features']]\n",
    "url = [f['properties']['url'] for f in data['features']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "570a26a8-c879-4705-894d-ece7fb3f65e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../../data/json_data.csv\",\"w\",encoding='utf-8') as f:\n",
    "    fieldnames = ['magnitude','location','url']\n",
    "    writer = csv.DictWriter(f, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    for mag,loc,u in zip(magnitude,location,url):\n",
    "        writer.writerow({'magnitude': mag, 'location': loc,'url':u})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31c28847-4435-4e97-acca-b8e556776a02",
   "metadata": {},
   "source": [
    "## Class Assignment\n",
    "\n",
    "Use the same datset as above and now filter out the places where the magnitude was more than 1.8. You can either use the json version or the csv you have created in the above excercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "255dcaa8-3491-4a8d-b3b7-56cc339c5cdf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
